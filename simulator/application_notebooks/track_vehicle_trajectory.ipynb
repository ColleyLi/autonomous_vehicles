{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Track Vehicle Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Extended Kalman filter:** https://en.wikipedia.org/wiki/Extended_Kalman_filter\n",
    "2. **Extended Kalman Filter Lecture Notes:** https://www.cs.cmu.edu/~motionplanning/papers/sbp_papers/kalman/ekf_lecture_notes.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Vehicle Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this application we will be recursively estimating a vehicle trajectory using available measurements and motion model. \n",
    "The vehicle is equipped with a LIDAR sensor, which returns range and bearing measurements corresponding to individual landmarks in the environment. The correspondences between landmarks and their global positions are assumed to be known beforehand. We also assume knowledge about which measurement belongs to which landmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion and measurement models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motion model recieves the linear and angular velocity odometry readings as inputs, and outputs the state (2D pose) of the vehicle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\mathbf{x}_{k} &= \\mathbf{x}_{k-1} + T\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta_{k-1} &0 \\\\\n",
    "\\sin\\theta_{k-1} &0 \\\\\n",
    "0 &1\n",
    "\\end{bmatrix}\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "v_k \\\\\n",
    "\\omega_k\n",
    "\\end{bmatrix}\n",
    "+ \\mathbf{w}_k\n",
    "\\right)\n",
    "\\, , \\, \\, \\, \\, \\, \\mathbf{w}_k = \\mathcal{N}\\left(\\mathbf{0}, \\mathbf{Q}\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{x}_k = \\left[ x \\, y \\, \\theta \\right]^T$ is the current 2D pose of the vehicle\n",
    "- $v_k$ and $\\omega_k$ are the linear and angular velocity odometry readings, which we are using as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process noise $\\mathbf{w}_k$ has a normal distribution with a constant covariance $\\mathbf{Q}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measurement model relates the current pose of the vehicle to the LIDAR range and bearing measurements $\\mathbf{y}^l_k = \\left[r \\, \\phi \\right]^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\mathbf{y}^l_k =\n",
    "\\begin{bmatrix}\n",
    "\\sqrt{(x_l - x_k - d\\cos\\theta_{k})^2 + (y_l - y_k - d\\sin\\theta_{k})^2} \\\\\n",
    "atan2\\left(y_l - y_k - d\\sin\\theta_{k},x_l - x_k - d\\cos\\theta_{k}\\right) - \\theta_k\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\mathbf{n}^l_k\n",
    "\\, , \\, \\, \\, \\, \\, \\mathbf{n}^l_k = \\mathcal{N}\\left(\\mathbf{0}, \\mathbf{R}\\right)\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x_l$ and $y_l$ are the ground truth coordinates of the landmark $l$\n",
    "- $x_k$ and $y_k$ and $\\theta_{k}$ represent the current pose of the vehicle\n",
    "- $d$ is the known distance between robot center and laser rangefinder (LIDAR)\n",
    "\n",
    "The landmark measurement noise $\\mathbf{n}^l_k$ has a normal distribution with a constant covariance $\\mathbf{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the above models are nonlinear, we recommend using the Extended Kalman Filter (EKF) as the state estimator.\n",
    "Specifically, you will need to provide code implementing the following steps:\n",
    "\n",
    "- the prediction step, which uses odometry measurements and above motion model to provide a state and covariance estimate at a given timestep\n",
    "- the correction step, which uses the range and bearing measurements provided by the LIDAR to correct the estimates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpack data\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's unpack the available data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need these so that Jupyter can find the simulator types\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('data/vehicle_trajectory/data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "t = data['t']  # timestamps [s]\n",
    "\n",
    "# input signal\n",
    "v = data['v']  # translational velocity input [m/s]\n",
    "om = data['om']  # rotational velocity input [rad/s]\n",
    "\n",
    "# bearing and range measurements, LIDAR constants\n",
    "b = data['b']  # bearing to each landmarks center in the frame attached to the laser [rad]\n",
    "r = data['r']  # range measurements [m]\n",
    "l = data['l']  # x,y positions of landmarks [m]\n",
    "d = data['d']  # distance between robot center and laser rangefinder [m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Remark**\n",
    "\n",
    "Note that distance from the LIDAR frame to the robot center is provided and loaded as an array into the `d` variable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If available, it is useful to plot the ground truth position and orientation out before starting the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"img/gtruth.png\" alt=\"Ground Truth\" width=\"350\"/> </td>\n",
    "<td> <img src=\"img/gtruth2.png\" alt=\"Ground Truth\" width=\"350\"/> </td>\n",
    "</tr></table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the orientation values are wrapped to the $\\left[-\\pi,\\pi\\right]$ range in radians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing parameters\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is loaded, we can start getting things ready for our solver. One of the\n",
    "most important aspects of a filter is setting the input and measurement noise covariance matrices, as well as the initial state and covariance values. We set the values here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_var = 0.01  # translation velocity variance  \n",
    "om_var = 0.01  # rotational velocity variance \n",
    "r_var = 0.1  # range measurements variance\n",
    "b_var = 0.1  # bearing measurement variance\n",
    "\n",
    "Q_km = np.diag([v_var, om_var]) # input noise covariance \n",
    "cov_y = np.diag([r_var, b_var])  # measurement noise covariance \n",
    "\n",
    "x_est = np.zeros([len(v), 3])  # estimated states, x, y, and theta\n",
    "P_est = np.zeros([len(v), 3, 3])  # state covariance matrices\n",
    "\n",
    "x_est[0] = np.array([0.0, 0.0, 0.0]) # initial state\n",
    "P_est[0] = np.diag([1, 1, 0.1]) # initial state covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Remark**\n",
    "\n",
    "Remember that it is neccessary to tune the measurement noise variances `r_var`, `b_var` in order for the filter to perform well.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the orientation estimates to coincide with the bearing measurements, it is neccessary to wrap all estimated $\\theta$ values to the $(-\\pi , \\pi)$ range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wraps angle to [-pi,pi] range\n",
    "def wraptopi(x):\n",
    "    if x > np.pi:\n",
    "        x = x - (np.floor(x / (2 * np.pi)) + 1) * 2 * np.pi\n",
    "    elif x < -np.pi:\n",
    "        x = x + (np.floor(x / (-2 * np.pi)) + 1) * 2 * np.pi\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Correction step\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's implement the measurement update function, which takes an available landmark measurement $l$ and updates the current state estimate $\\mathbf{\\check{x}}_k$. For each landmark measurement in a given timestep $k$ you should implement the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the measurement model Jacobians at $\\mathbf{\\check{x}}_{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\mathbf{y}^l_k = &\\mathbf{h}(\\mathbf{x}_{k}, \\mathbf{n}^l_k) \\\\\\\\\n",
    "\\mathbf{H}_{k} = \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{x}_{k}}\\bigg|_{\\mathbf{\\check{x}}_{k},0}& \\, , \\, \\, \\, \\,\n",
    "\\mathbf{M}_{k} = \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{n}_{k}}\\bigg|_{\\mathbf{\\check{x}}_{k},0} \\, .\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the Kalman Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbf{K}_k &= \\mathbf{\\check{P}}_k \\mathbf{H}_k^T \\left(\\mathbf{H}_k \\mathbf{\\check{P}}_k \\mathbf{H}_k^T + \\mathbf{M}_k \\mathbf{R}_k \\mathbf{M}_k^T \\right)^{-1} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Correct the predicted state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\mathbf{\\check{y}}^l_k &= \\mathbf{h}\\left(\\mathbf{\\check{x}}_k, \\mathbf{0}\\right) \\\\\n",
    "\\mathbf{\\hat{x}}_k &= \\mathbf{\\check{x}}_k + \\mathbf{K}_k \\left(\\mathbf{y}^l_k - \\mathbf{\\check{y}}^l_k\\right)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correct the covariance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbf{\\hat{P}}_k &= \\left(\\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right)\\mathbf{\\check{P}}_k\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meas_jacobian(lk, d_k, x_check):\n",
    "    \n",
    "    x_k = x_check[0]\n",
    "    x_l = lk[0]\n",
    "    y_k = x_check[1]\n",
    "    y_l = lk[1] \n",
    "    theta_k = x_check[2]\n",
    "    d = d_k\n",
    "    \n",
    "    # diff(sqrt((x_l - x_k - d*cos(theta_k))**2 + (y_l - y_k - d*sin(theta_k))**2), x_k)\n",
    "    # (d*cos(theta_k) + x_k - x_l)/sqrt((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2)\n",
    "    denom = np.sqrt((-d*np.sin(theta_k) - y_k + y_l)**2 + (-d*np.cos(theta_k) - x_k +x_l)**2)\n",
    "    partial_x_k_0 = (d*np.cos(theta_k) + x_k - x_l)/denom\n",
    "    \n",
    "    # diff(sqrt((x_l - x_k - d*cos(theta_k))**2 + (y_l - y_k - d*sin(theta_k))**2), y_k)\n",
    "    # (d*sin(theta_k) + y_k - y_l)/sqrt((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2)\n",
    "    partial_y_k_0 = (d*np.sin(theta_k) + y_k - y_l)/denom\n",
    "    \n",
    "    # diff(sqrt((x_l - x_k - d*cos(theta_k))**2 + (y_l - y_k - d*sin(theta_k))**2), theta_k)\n",
    "    # (-d*(-d*sin(theta_k) - y_k + y_l)*cos(theta_k) + d*(-d*cos(theta_k) - x_k + x_l)*sin(theta_k))/\n",
    "    # sqrt((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2)\n",
    "    \n",
    "    nom = (-d*(-d*np.sin(theta_k) - y_k + y_l)*np.cos(theta_k) + d*(-d*np.cos(theta_k) - x_k + x_l)*np.sin(theta_k))\n",
    "    partial_theta_k_0 = nom/denom\n",
    "    \n",
    "    # diff(atan2(y_l - y_k -d*sin(theta_k), x_l - x_k - d*cos(theta_k)) - theta_k, x_k)\n",
    "    # -(d*sin(theta_k) + y_k - y_l)/((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2)\n",
    "    nom = -(d*np.sin(theta_k) + y_k - y_l)\n",
    "    denom = ((-d*np.sin(theta_k) - y_k + y_l)**2 + (-d*np.cos(theta_k) - x_k + x_l)**2)\n",
    "    partial_x_k_1 = nom /denom\n",
    "    \n",
    "    # diff(atan2(y_l - y_k -d*sin(theta_k), x_l - x_k - d*cos(theta_k)) - theta_k, y_k)\n",
    "    # -(-d*cos(theta_k) - x_k + x_l)/((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2)\n",
    "    nom = -(-d*np.cos(theta_k) - x_k + x_l)\n",
    "    denom = ((-d*np.sin(theta_k) - y_k + y_l)**2 + (-d*np.cos(theta_k) - x_k + x_l)**2)\n",
    "    partial_y_k_1 = nom /denom\n",
    "    \n",
    "    # diff(atan2(y_l - y_k -d*sin(theta_k), x_l - x_k - d*cos(theta_k)) - theta_k, theta_k)\n",
    "    # d*(d*sin(theta_k) + y_k - y_l)*sin(theta_k)/\n",
    "    #((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2) - d*(-d*cos(theta_k) - x_k + x_l)*cos(theta_k)/((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2) - 1\n",
    "    nom = d*(d*np.sin(theta_k) + y_k - y_l)*np.sin(theta_k)\n",
    "    denom_1 = ((-d*np.sin(theta_k) - y_k + y_l)**2 + (-d*np.cos(theta_k) - x_k + x_l)**2) - 1\n",
    "    denom = ((-d*np.sin(theta_k) - y_k + y_l)**2 + (-d*np.cos(theta_k) - x_k + x_l)**2) - d*(-d*np.cos(theta_k) - x_k + x_l)*np.cos(theta_k)/denom_1\n",
    "    partial_theta_k_1 = nom / denom\n",
    "    H_k = np.array([[partial_x_k_0, partial_y_k_0, partial_theta_k_0], \n",
    "                    [partial_x_k_1, partial_y_k_1, partial_theta_k_1 ]])\n",
    "    \n",
    "    M_k = np.array([1.0])\n",
    "    return H_k, M_k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_variance(K, H, P_check):\n",
    "    \n",
    "    K_times_H = np.dot(K, H)\n",
    "    I = np.identity(K_times_H.shape[0])\n",
    "    P_k = np.dot(I - K_times_H, P_check)\n",
    "    return P_k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_update(lk, rk, bk,  d, P_check, x_check):\n",
    "    \n",
    "    # 1. Compute measurement model Jacobian\n",
    "    H_k, M_k = compute_meas_jacobian(lk=lk, d_k=d, x_check=x_check)\n",
    "\n",
    "    # 2. Compute Kalman Gain\n",
    "    H_k_T = H_k.T\n",
    "    H_k_P_check_H_T = np.dot(H_k, np.dot(P_check, H_k_T))\n",
    "    M_k_R_k_M_T = np.dot(M_k, np.dot(rk, M_k.T))\n",
    "    K_k = np.dot(np.dot(P_check, H_k.T),inv(H_k_P_check_H_T + M_k_R_k_M_T))\n",
    "    \n",
    "    y_check = np.ones(x_check.shape)\n",
    "\n",
    "    # 3. Correct predicted state (remember to wrap the angles to [-pi,pi])\n",
    "    x_check = x_check + K_k*(y_check)\n",
    "    \n",
    "    x_check[2] = wraptopi(x_check[2])\n",
    "\n",
    "    # 4. Correct covariance\n",
    "    P_check = correct_variance(K, H_k, P_check)\n",
    "\n",
    "    return x_check, P_check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction step\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement the main filter loop, implementing the prediction step of the EKF using the provided motion model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{\\check{x}}_k &= \\mathbf{f}\\left(\\mathbf{\\hat{x}}_{k-1}, \\mathbf{u}_{k-1}, \\mathbf{0} \\right) \\\\\n",
    "\\mathbf{\\check{P}}_k &= \\mathbf{F}_{k-1}\\mathbf{\\hat{P}}_{k-1}\\mathbf{F}_{k-1}^T + \\mathbf{L}_{k-1}\\mathbf{Q}_{k-1}\\mathbf{L}_{k-1}^T \\, .\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbf{F}_{k-1} = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}_{k-1}}\\bigg|_{\\mathbf{\\hat{x}}_{k-1},\\mathbf{u}_{k},0}  \\, , \\, \\, \\, \\,\n",
    "\\mathbf{L}_{k-1} = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{w}_{k}}\\bigg|_{\\mathbf{\\hat{x}}_{k-1},\\mathbf{u}_{k},0} \\, .\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape P_est:  (3, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-faf34fea0dc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# 5. Update state estimate using available landmark measurements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_check\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeasurement_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_check\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mP_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_check\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Set final state predictions for timestep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-972828053c20>\u001b[0m in \u001b[0;36mmeasurement_update\u001b[1;34m(lk, rk, bk, d, P_check, x_check)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mH_k_P_check_H_T\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_k_T\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mM_k_R_k_M_T\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mK_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_k_P_check_H_T\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mM_k_R_k_M_T\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0my_check\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inv' is not defined"
     ]
    }
   ],
   "source": [
    "#### 5. Main Filter Loop #######################################################################\n",
    "for k in range(1, len(t)):  # start at 1 because we've set the initial prediciton\n",
    "\n",
    "    delta_t = t[k] - t[k - 1]  # time step (difference between timestamps)\n",
    "\n",
    "    # 1. Update state with odometry readings (remember to wrap the angles to [-pi,pi])\n",
    "    x_check = np.zeros(3)\n",
    "\n",
    "    # 2. Motion model jacobian with respect to last state\n",
    "    F_km = np.zeros([3, 3])\n",
    "\n",
    "    # 3. Motion model jacobian with respect to noise\n",
    "    L_km = np.zeros([3, 2])\n",
    "    \n",
    "    print(\"shape P_est: \",P_est[0].shape )\n",
    "\n",
    "    # 4. Propagate uncertainty\n",
    "    P_check = np.dot(F_km, np.dot(P_est[0], F_km.T)) + np.dot(L_km, np.dot(Q_km, L_km.T))\n",
    "\n",
    "    # 5. Update state estimate using available landmark measurements\n",
    "    for i in range(len(r[k])):\n",
    "        x_check, P_check = measurement_update(l[i], r[k, i], b[k, i], P_check=P_check, x_check=x_check, d=d)\n",
    "\n",
    "    # Set final state predictions for timestep\n",
    "    x_est[k, 0] = x_check[0]\n",
    "    x_est[k, 1] = x_check[1]\n",
    "    x_est[k, 2] = x_check[2]\n",
    "    P_est[k, :, :] = P_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the resulting state estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_fig = plt.figure()\n",
    "ax = e_fig.add_subplot(111)\n",
    "ax.plot(x_est[:, 0], x_est[:, 1])\n",
    "ax.set_xlabel('x [m]')\n",
    "ax.set_ylabel('y [m]')\n",
    "ax.set_title('Estimated trajectory')\n",
    "plt.show()\n",
    "\n",
    "e_fig = plt.figure()\n",
    "ax = e_fig.add_subplot(111)\n",
    "ax.plot(t[:], x_est[:, 2])\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel('theta [rad]')\n",
    "ax.set_title('Estimated trajectory')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you satisfied wth your results? The resulting trajectory should closely resemble the ground truth, with minor \"jumps\" in the orientation estimate due to angle wrapping. If this is the case, run the code below to produce your solution file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.pkl', 'wb') as f:\n",
    "    pickle.dump(x_est, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
