{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Support Vector Machines Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Support-vector machine:** https://en.wikipedia.org/wiki/Support-vector_machine\n",
    "2. **Support Vector Machines**: https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines or SVMs are a set of supervised learning methods used for classification, regression amd outliers detection. At first approximation, what SVMs do is to find a separation line or more generally a hyperplane between the data of two classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The separation line tries to maximize the distance between the line and the nearest point. This makes the algorithm more robust. Nonetheless, SVMs try first to have a correct classification and then try to maximize the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the advantages of SVMs are [2]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Effective in high dimensional spaces\n",
    "- Effective in cases where the number of dimensions is greater than the number of samples\n",
    "- Memory efficient as they use a subset of training points in the decision function\n",
    "- Different kernel functions can be specified for the decision function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, SVMs have disadvantages also which include [2]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the number of features is much greater than the number of samples, then the choice of the kernel function becomes crucial when dealing with overfitting.\n",
    "- SVMs do not directly provide probability estimates. These can be calculated using five-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVMs in ```sklearn```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0,0], [1,1]]\n",
    "y = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier. Note that we can also set the kernel type:\n",
    "# clf = svm.SVC(kernel='linear')\n",
    "# The C option controls the tradeoff between smooth decision boundary and classifying trainig points correctly\n",
    "# Hence  a large value of C we get more points classified correctly. Thus the decision boundary will be more wigly\n",
    "# the \\gamma parameter defines how far the influence of a single training example reaches\n",
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Remark**\n",
    "\n",
    "The $\\gamma$ parameter has no effect when we use a linear kernel\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the ```SVC``` class is two arrays; one of size ```[n_samples, n_features]```, that holds the training examples, and an array that holds the class labels which can be either strings or integers that has size ```[n_samples]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [[2., 2.]]\n",
    "test_labels = [1]\n",
    "pred = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Remark**\n",
    "\n",
    "SVMs decision function depends on some subset of the training data, called the support vectors. Some properties of these support vectors can be found in \n",
    "\n",
    "- ```support_vectors_``` which gives  the support vectors\n",
    "- ```support_``` which gives the indices of the support vectors\n",
    "- ```n_support_``` which is the numbers of support vectors for each class\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(pred, test_labels)\n",
    "print(\"Accuracy is \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM: Maximum margin separating hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "# we create 40 separable points\n",
    "X, y = make_blobs(n_samples=40, centers=2, random_state=6)\n",
    "\n",
    "# fit the model, don't regularize for illustration purposes\n",
    "clf = svm.SVC(kernel='linear', C=1000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "# plot the decision function\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "# plot support vectors\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
