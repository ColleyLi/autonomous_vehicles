\chapter{State Feedback}
\label{state_feedback}

The state, $x(t)$, of a dynamical system is a collection of variables that permits prediction
of the future development of a system. In this chapter we want to  explore the idea of designing
the dynamics of a system through feedback of the state.  A typical feedback control system with state feedback
is shown in figure \ref{state_feedback_sys}

\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/state_feedback_sys.jpeg}
\end{center}
\caption{A feedback control system with state feedback. The controller uses the system
state $x$ and the reference input $r$ to command the process through its input $u$. We model
disturbances via the additive input $d$.}
\label{state_feedback_sys}
\end{figure}


The goal of the feedback controller is to regulate the output of the system $y$ such that it tracks the reference input in the presence of disturbances and also uncertainty in the process dynamics.

\section{Overview}
We have already mentioned the general form of the state-space model is 

\begin{eqnarray}
\dot{x} = f(x, u, d) \\
y = h(x,u,d)
\end{eqnarray}

both $f$ and $h$ can be nonlinear functions of their arguments however in this section we will assume that we are dealing with a linear system. Our aim is
to design a state feedback controller. Thus, let's consider again the system

\begin{eqnarray}
\dot{x} = Ax + Bu \\
y = Cx + Du
\end{eqnarray}

The poles of the system are given by the eigenvalues of the matrix $A$ which are the roots of the characteristic polynomial

\begin{equation}
det(sI-A) = 0
\end{equation}

Feedback control is a method for shaping the dynamics of the system. This is done by modifying the eigenvalues of the system using the input $u$. Indeed, let's assume that $u$
can be written as 

\begin{equation}
u = -Kx + K_r r
\end{equation}

with $K \in r^{p\times n}$, $k_r \in R^{p\times r}$ and $r \in R^r$ is the reference input. We can shape the dynamics of the system via the feedback gain $K$. $K_r$ is used to change the steady state level
of the system. The system dynamics becomes

\begin{eqnarray}
\dot{x} = Ax + B(-Kx + K_r r) \\
 = (A-BK)x + BK_r r
\end{eqnarray}

The control objective now is to choose $K$ such that the closed loop dynamics $A-BK$ get the desired properties.



\begin{framed}
\theoremstyle{remark}
\begin{remark}{\textbf{Steady state reference gain}}

The steady-state reference gain $K_r$ does not affect the stability of the system but it does affect the steady state solution.
\end{remark}
\end{framed}


The gain $K_r$ is chosen such that 

\begin{equation}
y(t) \approx r(t), ~~ \text{as} ~~ t \rightarrow \infty
\end{equation}

At steady state

\begin{equation}
\dot{x} = 0 
\end{equation}

thus we can write


\begin{eqnarray}
0 = (A-BK)x + BK_r r \\
y = Cx 
\end{eqnarray}


Hence, we can write for the output $y$


\begin{equation}
y = -C(A-Bk)^{-1}BK_r r 
\end{equation}

If we want $y(t) \approx r(t)$, as $ t \rightarrow \infty$, then $K_r$ should be chosen as

\begin{equation}
K_r = - ( C(A-BK)^{-1}B)^{-1} 
\end{equation}

The design of the controller becomes a two step process.

\begin{itemize}

\item shape the dynamics by choosing $K$
\item set the steady-state level by choosing $K_r$
\end{itemize}

This way the reference gain depends on the feedback gain. Using the steady-state feedback gain $K_r$ we can achieve zero steady-state error but this depends on the model parameters also. Integration can be used in order to remove the steady-state error. This can be done by introducing a new variable to remove the steady-state error:

We will illustrate how  this is done assuming a SISO system. 

\begin{equation}
\dot{z}(t) = y(t) - r(t)
\end{equation}

The new state-space model becomes


\begin{equation}
\begin{bmatrix}
 \dot{x} \\
 \dot{z} 
\end{bmatrix} = 
\begin{bmatrix}
 Ax-Bu \\
 y-r 
\end{bmatrix} = 
\begin{bmatrix}
 Ax-Bu \\
 Cx-r  
\end{bmatrix}
\end{equation}


the above can be written as

\begin{equation}
\begin{bmatrix}
 A & 0 \\
 0 & 0 
\end{bmatrix} +  
\begin{bmatrix}
 B \\
 0 
\end{bmatrix}u +
\begin{bmatrix}
 0 \\
 -1  
\end{bmatrix}r
\end{equation}

Thus, the new controller now becomes

\begin{equation}
u(t) = - Kx(t) - K_I z(t) + K_r r(t)
\end{equation}

\section{Reachability}
One of the fundamental properties of a control system is what set of points in the
state space can be reached through the choice of a control input. It turns out that the
property of reachability is also fundamental in understanding the extent to which
feedback can be used to design the dynamics of a system.

\begin{framed}
\theoremstyle{definition}
\begin{definition}{Reachability}

A linear system is reachable if for any $x_0, x_f \in R^n$ there exists a $T > 0$ and $u: [0,T] \rightarrow R$ such tha the corresponding solution satisfies $x(0) = x_0$ and $x(T) = x_f$.
\end{definition}
\end{framed}


\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/reachability.jpeg}
\end{center}
\caption{The reachable set for a control system. The set $R(x_0,\leq T )$ shown in (a) is the set
of points reachable from $x_0$ in time less than $T$ . The phase portrait in (b) shows the dynamics
for a double integrator, with the natural dynamics drawn as horizontal arrows and the control
inputs drawn as vertical arrows. The set of achievable equilibrium points is the $x$ axis. By
setting the control inputs as a function of the state, it is possible to steer the system to the
origin, as shown on the sample path.}
\label{reachability}
\end{figure}


The definition of reachability addresses whether it is possible to reach all points
in the state space in a transient fashion. In many applications, the set of points that
we are most interested in reaching is the set of equilibrium points of the system
(since we can remain at those points once we get there). The set of all possible
equilibria for constant controls is given by:

\begin{equation}
E = { x_e: Ax_e + Bu_e = 0 ~~ \text{for some} ~~ u_e \in R }
\end{equation}

To find general conditions under which a linear system is reachable, we will
first give a heuristic argument based on formal calculations with impulse functions.

\begin{framed}
\theoremstyle{remark}
\begin{remark}{Equilibrium points and reachability}

We note that if we can reach all points in the state space through some choice of
input, then we can also reach all equilibrium points.
\end{remark}
\end{framed}

\subsection{Testing for reachability with impulse functions}

When the initial state is zero, the resppnse of the system to an input $u(t)$ is given by

\begin{equation}
x(t) = \int_{0}^{t} e^{A(t-\tau)}Bu(\tau)d\tau
\end{equation}

Let's choose the input to be an impulse function $\delta(t)$. The state then becomes

\begin{framed}
\theoremstyle{remark}
\begin{remark}{Impulse function $\delta(t)$}

\end{remark}
\end{framed}

\begin{equation}
x_{\delta}  = \int_{0}^{t} e^{A(t-\tau)}Bu(\tau)d\tau = \frac{dx_s}{dt} = e^{At}B
\end{equation}

(Note that the state changes instantaneously in response to the impulse.) We can
find the response to the derivative of an impulse function by taking the derivative
of the impulse response (Exercise 5.1):

\begin{equation}
\frac{dx_{\delta}}{dt} = Ae^{At}B
\end{equation}

Continuing this process and using the linearity of the system, the input

\begin{equation}
u(t) = \alpha_1\delta(t) + \alpha_2 \frac{d\delta(t)}{dt} + \dots +  \alpha_n \frac{d^{n-1}\delta(t)}{dt^{n-1}}  
\end{equation}

gives the state

\begin{equation}
x(t) = \alpha_1e^{At}B + \alpha_2Ae^{At}B + \dots +  \alpha_n A^{n-1}e^{At}B  
\end{equation}

On the right is a linear combination of the columns of the matrix

\begin{equation}
W_r = \begin{bmatrix}
 B & AB & \ldots & A^{n-1}B 
\end{bmatrix}
\end{equation}

To reach an arbitrary point  in the state  space,  we  thus  require that there are $n$ linear independent columns of the matrix $W_r$. 

\begin{framed}
\theoremstyle{remark}
\begin{remark}{\textbf{The reachability matrix $W_r$}}

The matrix $W_r$ is called the reachability
matrix.

\end{remark}
\end{framed}

\subsection{Testing for reachability with the convolution equation}

However, an input $u(t)$ consisting of a sum of impulse functions and their derivatives is a very
violent signal. To see that an arbitrary point can be reached with smoother signals we can make use of the convolution equation. Assuming that the initial condition is zero, the state of a linear system is given by
\begin{equation}
x(t)  = \int_{0}^{t} e^{A(t-\tau)}Bu(\tau)d\tau = \int_{0}^{t} e^{A(\tau)}Bu(t-\tau)d\tau
\end{equation}

It follows from the theory of matrix functions, specifically the Cayley-Hamilton
theorem (see Exercise 6.10), that


\begin{framed}
\theoremstyle{remark}
\begin{remark}{The Cayley-Hamilton theorem}

\end{remark}
\end{framed}

\begin{equation}
e^{A\tau}  = I\alpha_0(\tau) + A\alpha_1(\tau) + \dots + A^{n-1}\alpha_{n-1}(\tau)
\end{equation}

where $\alpha_i$ are scalar functions, and we find that 

\begin{equation}
x(t)  = B\int_{0}^{t} \alpha_0(\tau)u(t-\tau)d\tau + AB\int_{0}^{t} \alpha_1(\tau)u(t-\tau)d\tau+ \dots + A^{n-1}B\int_{0}^{t} \alpha_{n-1}(\tau)u(t-\tau)d\tau  
\end{equation}

Again we observe that the right-hand side is a linear combination of the columns
of the reachability matrix $W_r$ given by equation (6.3). This basic approach leads to
the following theorem.

\begin{framed}
\theoremstyle{theorem}
\begin{theorem}{Reachability rank condition}

 A linear system is reachable if and
only if the reachability matrix $W_r$ is invertible.
\end{theorem}
\end{framed}


\subsection{Reachable Canonical Form}
\label{reachable_canonical_form}

It is often convenient to change coordinates and write the dynamics of the system in the transformed coordinates

\begin{equation}
z = Tx
\end{equation}

One application of a change of coordinates is to convert a system into a
canonical form in which it is easy to perform certain types of analysis.

\begin{framed}
\theoremstyle{remark}
\begin{remark}{\textbf{Reachable Canonical Form}}

A linear state space system is in reachable canonical form, if its dynamics are given by

\begin{eqnarray}
\frac{dz}{dt} = Az + Bu \\
y=Cz + du
\end{eqnarray}

\end{remark}
\end{framed}

The characteristic polynomial for a system in reachable canonical form is given

\begin{equation}
\lambda(s) = s^n +\alpha_1s^{n-1}+ \dots + \alpha_{n-1}s + \alpha_n
\end{equation}

The reachability matrix also has a relatively simple structure:

We now consider the problem of changing coordinates such that the dynamics
of a system can be written in reachable canonical form. Let $A$, $B$ represent the
dynamics of a given system and $\tilde{A}, \tilde{B}$ be the dynamics in reachable canonical form.
Suppose that we wish to transform the original system into reachable canonical
form using a coordinate transformation $z = Tx$. As shown in the last chapter, the
dynamics matrix and the control matrix for the transformed system are

\begin{equation}
\tilde{A} = TAT^{-1}, ~~ \tilde{B} = TB
\end{equation}

The reachability matrix for the transformed system then becomes

\begin{equation}
\tilde{W}_r = \begin{bmatrix}
 \tilde{B} & \tilde{A}\tilde{B} & \ldots & \tilde{A}^{n-1}\tilde{B} 
\end{bmatrix}
\end{equation}

We can transforming each element individually and thus get the reachability matrix fro the transformed system

\begin{equation}
\tilde{W}_r = TW_r
\end{equation}

However, we know that $W_r$ is invertible. Therefore we can solve for the transformation $T$ that takes the system into reachable canonical form:

\begin{equation}
T = \tilde{W}_r W_{r}^{-1}
\end{equation}


\begin{framed}
\theoremstyle{theorem}
\begin{theorem}{Reachable canonical form}

Let $A$ and $B$ be the dynamics and control matrices for a reachable system. Then there exists a transformation

\begin{equation}
z = Tx \nonumber
\end{equation}

such that in the transformed coordinates  the dynamics and control matrices are in the reachable 
canoinical form and the characteristic polynomial for $A$ is given by

\begin{equation}
\text{det}(sI-A) = 0 \nonumber
\end{equation}

\end{theorem}
\end{framed}

One important implication of this theorem is that for any reachable system, we
can assume without loss of generality that the coordinates are chosen such that the
system is in reachable canonical form. This is particularly useful for proofs, as we
shall see later in this chapter. However, for high-order systems, small changes in
the coefficients $a_i$ (that is the coefficients of the characteristic polynomial) can give large changes in the eigenvalues. Hence, the reachable canonical form is not always well conditioned and must be used with some care.


\section{Stabilization by State Feedback}

In this section, we will assume that the
system to be controlled is described by a linear state model and has a single input
(for simplicity). The feedback control law will be developed step by step using a
single idea: the positioning of closed loop eigenvalues in desired locations.

Figure \ref{state_feedback_sys_II} has already been shown at the begining of this chapter. It shows a diagram of a typical control system using state feedback.


\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/state_feedback_sys.jpeg}
\end{center}
\caption{A feedback control system with state feedback. The controller uses the system
state $x$ and the reference input $r$ to command the process through its input $u$. We model
disturbances via the additive input $d$.}
\label{state_feedback_sys_II}
\end{figure}

The full system consists of the process dynamics, which we take to be linear, the controller
elements $K$ and $k_r$ , the reference input (or command signal) $r$ and process disturbances $d$. The goal of the feedback controller is to regulate the output of the system $y$ such that it tracks the reference input in the presence of disturbances and also uncertainty in the process dynamics.

An important element of the control design is the performance specification.
The simplest performance specification is that of stability: in the absence of any
disturbances, we would like the equilibrium point of the system to be asymptotically
stable. More sophisticated performance specifications typically involve giving desired properties of the step or frequency response of the system, such as specifying the desired rise time, overshoot and settling time of the step response. Finally, we are often concerned with the disturbance attenuation properties of the system: to
what extent can we experience disturbance inputs $d$ and still hold the output $y$ near the desired value?

Consider a system described by the linear differential equation



\begin{equation}
\frac{dx}{dt} = Ax + Bu ~~ y = Cx + Du
\end{equation}


\section{Example: Vehicle Steering}

Let's sum up the major topics we discussed above by considering vehicle steering. A common problem in motion conrol is to control
the trajectory of a vehicle through an actuator that causes a change in the orientation. 


\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/vehicle_steering.jpeg}
\end{center}
\caption{Vehicle steering dynamics. The left figure shows an overhead view of a vehicle
with four wheels. The wheel base is $b$ and the center of mass at a distance a forward of the
rear wheels. By approximating the motion of the front and rear pairs of wheels by a single
front wheel and a single rear wheel, we obtain an abstraction called the bicycle model, shown
on the right. The steering angle is $\delta$ and the velocity at the center of mass has the angle $\alpha$
relative the length axis of the vehicle. The position of the vehicle is given by ($x, y)$ and the orientation (heading) by $\theta$.}
\label{vehicle_steering}
\end{figure}

Let's consider a vehicle with two wheels. We are intersted in how the velocity of the steering depends on the steering angle $\delta$.
Specifically, consider the velocity $v$ at the center
of mass, a distance $w$ from the rear wheel, and let $b$ be the wheel base, as shown
in Figure \ref{vehicle_steering}. Let $(x, y)$ be the coordinates of the center of mass, $\theta$ the heading
angle and $\alpha$ the angle between the velocity vector $v$ and the centerline of the vehicle.
Since $b = r_w\tan(\delta)$ and $w = r_w\tan(\alpha)$, it follows that $\tan(\alpha) = (w/b) \tan(\delta)$ and we get
the following relation between $\alpha$ and the steering angle $\delta$:

\begin{equation}
\alpha(\delta) = \text{arctan}(\frac{w\tan(\delta)}{b})
\end{equation}

Let's assume that the wheels are rolling without slip and that the velocity of the rear
wheel is $v_0$. The vehicle speed at its center of mass is 

\begin{equation}
v = \frac{v_0}{\cos(\alpha)}
\end{equation}
we find that the motion of this point is described  by

\begin{eqnarray}
\frac{dx}{dt} = v\cos(\alpha + \theta) = v_0 \frac{\cos(\alpha + \theta)}{\cos(\alpha)} \label{vehicle_steering_model_I_eq_1}\\
\frac{dy}{dt} = v\sin(\alpha + \theta) = v_0 \frac{\sin(\alpha + \theta)}{\cos(\alpha)} \label{vehicle_steering_model_I_eq_2}\\
\frac{d\theta}{dt} = \frac{v_0}{r_w} = \frac{v_0}{b} \tan(\delta) 
\label{vehicle_steering_model_I_eq_3}
\end{eqnarray}


Equations \ref{vehicle_steering_model_I_eq_1}-\ref{vehicle_steering_model_I_eq_3} can be used to model an automobile under the 
assumptions that there is no slip between the wheels and the road. Furthermore, the quations above
assume that the two front wheels can be approximated by a single wheel at the center of the car. 
The assumption of no slip can be relaxed by adding an extra state variable, giving a more
realistic model. Such a model also describes the steering dynamics of ships as well
as the pitch dynamics of aircraft and missiles.

We can represent these equations in a matrix form 

\begin{equation}
\frac{d}{dt}
\begin{bmatrix}
 x \\
 y  \\
 \theta 
\end{bmatrix} =
\begin{bmatrix}
 v\cos(\alpha(\delta) + \theta) \\
 v\sin(\alpha(\delta) + \theta)  \\
 \frac{v_0}{b} \tan(\delta) 
\end{bmatrix}, ~~ \alpha(\delta) = \text{arctan}(\frac{w\tan(\delta)}{b})
\end{equation}


We are interested in the motion of the vehicle about a straight-line path $(\theta = \theta_0 )$
with fixed velocity $v_0 \neq 0$. In order to find the relevant equilibrium point, 
we first set $\dot{\theta} = 0$. Then we see that we must have $\delta = 0$, corresponding to the steering wheel being
straight. This also yields $\alpha = 0$. 


Suppose now that we are concerned with the lateral deviation of the vehicle
from a straight line. For simplicity, we let $\theta_{e} = 0$, which corresponds to driving
along the $x$ axis. We can then focus on the equations of motion in the $(y, \theta)$ plain
Let's introduce  the state $\mathbf{x} = (x_1, x_2) = (y, \theta )$ and $u = \delta$. 
The system is then in standard form with

\begin{equation}
f(\mathbf{x}, u)=
\begin{bmatrix}
v\sin(\alpha(u) + x_2)  \\
 \frac{v_0}{b} \tan(u) 
\end{bmatrix}, ~~ \alpha(u) = \text{arctan}(\frac{w\tan(u)}{b}), ~~ h(\mathbf{x}, u) = x_1
\end{equation}

The  equilibrium  point  of  interest  is given  by $\mathbf{x} = (0, 0)$  and  $u = 0$.  
To compute  the linearized model around this equilibrium point, we make use of the formulas (5.34).
A straightforward calculation yields

\begin{eqnarray}
A = \frac{\partial f}{\partial x} =
 \begin{bmatrix}
   0 & v_0  \\
   0 & 0 
\end{bmatrix}, ~~
B = \frac{\partial f}{\partial u} =
 \begin{bmatrix}
   wv_0/b  \\
   v_0/b
\end{bmatrix} \\
C= \frac{\partial h}{\partial x} =
 \begin{bmatrix}
   1 & 0
\end{bmatrix}, ~~ D = \frac{\partial h}{\partial u} = 0
\end{eqnarray}

where the derivatives above are computed at the equilibrium points. Thus, we obtain the linearized system

\begin{equation}
\frac{d\mathbf{x}}{dt} = A\mathbf{x} + Bu, ~~ y=C\mathbf{x} + Du
\label{vehicle_steering_model_II}
\end{equation}

that provides an approximation to the original nonlinear dynamics.
The linearized model can be simplified further by introducing normalized variables. For this system, we choose the wheel base $b$ as the length unit.  The normalized state is thus $\mathbf{z} = (x_1/b, x_2 )$, 
and the new time variable is $\tau = v_0t/b$.
The model \ref{vehicle_steering_model_II} then becomes

\begin{equation}
\frac{d\mathbf{z}}{d\tau} = 
\begin{bmatrix}
   0 & 1 \\
   0 & 0
\end{bmatrix}\mathbf{z}+
\begin{bmatrix}
   \gamma \\
   1
\end{bmatrix}u,  ~~ y= 
\begin{bmatrix}
   1 & 0
\end{bmatrix}\mathbf{z}
\label{vehicle_steering_model_3}
\end{equation}
 
where $\gamma = w/b$. The  normalized  linear model for  vehicle  steering  with nonslipping wheels is thus a linear system with only one parameter.

The response in the dynamics is shown in the figures below

\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/lateral_position_response.png}
\end{center}
\caption{Response of the vehicle lateral position with respect to $\omega_n$.}
\label{lateral_position_response}
\end{figure}


\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/delta_response.png}
\end{center}
\caption{Response of the steering angle with respect  to $\omega_n$.}
\label{delta_response}
\end{figure}

\section{Exercises}

\subsubsection{Exercise 1}

Consider the system 

\begin{eqnarray}
\dot{x} = Ax + Bu \\
y = Cx 
\end{eqnarray}

controlled by a state feedback controller: 

\begin{equation}
 u = -Kx  
\end{equation}

What are  the sizes of the matrices A, B, C, and K if we have one input signal, three states and two output signals.

\textbf{Answer}

Since the state has three components then $A$ must be $3\times 3$. As we have only one input but the result of $Bu$ must be added to the result of $Ax$ then $B$ must be $3\times 1$.
Since the output has two components then $C$ must be $2\times 3$. Finally, $K$ must be $1\times 3$.

\subsubsection{Exercise 2}

Consider again the system in the previous  question. Assume now that but now the system has two input signals, three states and one output signal. What are the sizes of the involved matrices?

\textbf{Answer}

Using the same line of reasoning, since the state has three components then $A$ must be $3\times 3$. As we have only two input but the result of $Bu$ must be added to the result of $Ax$ then $B$ must be $3\times 2$. Since the output has two components then $C$ must be $1\times 3$. Finally, $K$ must be $2\times 3$.

\subsubsection{Exercise 3}

Consider again the system in the previous  question. Assume now that but now the system has two input signals, four states and one output signal. What are the sizes of the involved matrices?

\textbf{Answer}

Using the same line of reasoning, since the state has three components then $A$ must be $4\times 4$. As we have only two input but the result of $Bu$ must be added to the result of $Ax$ then $B$ must be $4\times 2$. Since the output has two components then $C$ must be $1\times 4$. Finally, $K$ must be $2\times 4$.

\subsubsection{Exercise 4}

Consider the mechanical system shown in Figure \ref{Mechanical_system_3_1_1_ex_4} 

\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/Mechanical_system_3_1_1_ex_4.png}
\end{center}
\caption{Schematic of mechanical system}
\label{Mechanical_system_3_1_1_ex_4}
\end{figure}

The system is described by the following state-space model

\begin{eqnarray}
\begin{bmatrix}
 \dot{x}_1 \\
 \dot{x}_2 
\end{bmatrix} =  
\begin{bmatrix}
 0 & 1 \\
 0 & -c/m
\end{bmatrix}
\begin{bmatrix}
 x_1 \\
 x_2  
\end{bmatrix}+
\begin{bmatrix}
 0 \\
 1/m  
\end{bmatrix}u \\
y =
\begin{bmatrix}
 1 & 0 
\end{bmatrix}
\begin{bmatrix}
 x_1 \\
 x_2  
\end{bmatrix}
\end{eqnarray}

where $x_1$ is the position of the mass, $x_2$ is the velocity of the mass and $u$ is the input signal, the force. The output $y$ is the position. Assume that the desired closed loop characteristic polynomial is

\begin{equation}
p(s) = s^2 + 2\zeta \omega_n s +\omega_{n}^{2}  
\end{equation}

and the state feedback controller is 

\begin{equation}
u = -Kx  
\end{equation}

Determine the elements of $K=[k_{11}, k_{12}]$

\textbf{Answer}

By substituting the expression for $u$ into the equation describing the state dynamics, we can write

\begin{equation}
\dot{x} = (A - BK)x
\end{equation}

We can now calculate the characteristic polynomial via


\begin{equation}
det(s I - (A - BK)) = 0
\end{equation}

This gives us a second order polynomial

\begin{equation}
s^2 + ((c + k_{12})/m)s + k_{11}/m
\end{equation}

by matching the coefficients with the desired closed loop characteristic polynomial, we get

\begin{equation}
k_{12} = 2 \zeta m\omega_{n} -c, ~~ k_{11} = m \omega_{n}^{2}
\end{equation}

\subsubsection{Exercise 5}

Consider the mechanical system shown in Figure \ref{Mechanical_system_3_1_1_ex_4} described by the same steady-state model. Assume that the feedback controller is

\begin{equation}
u = -Kx + K_r r 
\end{equation} 

where $r$ is the reference signal. We want to determine the steady state reference gain $K_r$ such that the steady-state level is 1.

\textbf{Answer}

The reference gain $K_r$ is given by 

\begin{equation}
K_r = - ( C(A-BK)^{-1}B)^{-1} 
\end{equation}

Thus, by substituting the values for $k_{11}$ and $k_{12}$ and performing the calculations, we arrive at 

\begin{equation}
K_r = m\omega_{n}^{2}
\end{equation}

\subsubsection{Exercise 6}

Consider the closed loop system with the controller designed as in the previous exercise. Determine the transfer function for closed loop system, from the reference signal to the output.  How many zeros does the system have?

\textbf{Answer}

The transfer function can be computed as

\begin{equation}
G_{ry}(s) = C(sI - A + BK)^{-1}BK_r \nonumber
\end{equation}

substituting the relevant quantities we arrive at

\begin{equation}
G_{ry}(s) = \frac{\omega_{n}^{2}}{s^2 + 2\zeta\omega_n s + \omega_{n}^{2}}  \nonumber
\end{equation}

the number of zeros is 0 as the numerator is constant.

\subsubsection{Exercise 7}

Consider the tank system as shown in  figure \ref{Watertank_09}.
\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/Watertank_09.png}
\end{center}
\caption{Watertank schematics.}
\label{Watertank_09}
\end{figure}
The watertank is modeled by

\begin{eqnarray}
\dot{h} = \frac{1}{A_t}q_0 + \frac{1}{A_t}d - \frac{\alpha}{A_t}\sqrt{2gh} \nonumber \\
q_1 = \alpha \sqrt{2gh}   \nonumber
\end{eqnarray}

where is $h$ the level in the tank, $q_0$ is the inflow, $d$ is the disturbance and $q_1$ is the outflow.
Linearize the tank system around the equilibrium point $(h_e, q_{0e}, d_e) = (h_0, q_0, 0)$. Determine the matrices $A$, $B$, $C$ and $H$ , and corresponding to the model:

\begin{eqnarray}
\Delta \dot{h} = A \Delta h + B \Delta q_0 + H \Delta d  \nonumber \\
\Delta q_1 = C \Delta h \nonumber  
\end{eqnarray}

\textbf{Answer}

Let's consider the following functions

\begin{eqnarray}
f(h,q_0,d) = \frac{1}{A_t}q_0 + \frac{1}{A_t}d - \frac{\alpha}{A_t}\sqrt{2gh} \nonumber \\
l(h, q_0, d) = \alpha \sqrt{2gh}   \nonumber
\end{eqnarray}

The linearized system can be determined as: 

\begin{eqnarray}
\Delta \dot{h} = \frac{\partial f}{\partial h} \Delta h + \frac{\partial f}{\partial q_0} \Delta q_0 + \frac{\partial f}{\partial d} \Delta d  \nonumber \\
\Delta q_1 = \frac{\partial l}{\partial h} \Delta h   \nonumber
\end{eqnarray}

The partial derivatives can be expressed as 

\begin{equation}
\frac{\partial f}{\partial h} = -\frac{\alpha \sqrt{2g}}{2A_t\sqrt{h}}, ~~ \frac{\partial f}{\partial q_0} = \frac{1}{A_t}, ~~ \frac{\partial f}{\partial d} = \frac{1}{A_t}, ~~ \frac{\partial l}{\partial h} = \frac{\alpha \sqrt{2g}}{2\sqrt{h}}    \nonumber
\end{equation}

Inserting the equilibrium point gives: 

\begin{eqnarray}
\Delta \dot{h} = -\frac{\alpha \sqrt{2g}}{2A_t\sqrt{h_0}} \Delta h + \frac{1}{A_t} \Delta q_0 + \frac{1}{A_t} \Delta d  \nonumber \\
\Delta q_1 = \frac{\alpha \sqrt{2g}}{2\sqrt{h_0}} \Delta h   \nonumber
\end{eqnarray}

Thus, the matrices are

\begin{equation}
A =-\frac{\alpha \sqrt{2g}}{2A_t\sqrt{h_0}}, ~~ B = \frac{1}{A_t}, ~~ H = \frac{1}{A_t}, ~~ C= \frac{\alpha \sqrt{2g}}{2\sqrt{h_0}} \nonumber
\end{equation}

\subsubsection{Exercise 8}

A leaf spring system is shown in figure \ref{Image_LeafSpringSuspension_01}

\begin{figure}[!htb]
\begin{center}
\includegraphics[scale=0.280]{img/state_feedback/Image_LeafSpringSuspension_01.jpg}
\end{center}
\caption{Leaf spring system.}
\label{Image_LeafSpringSuspension_01}
\end{figure}

The system can be described using the following nonlinear model: 

\begin{eqnarray}
\begin{bmatrix}
 \dot{x}_1\\
 \dot{x}_2
\end{bmatrix}= 
\begin{bmatrix}
 x_2  \\
 -\frac{k_1 x_1}{m} - \frac{k_2 x_{1}^3}{m}  
\end{bmatrix} \nonumber
\end{eqnarray}

Three equilibrium points was considered for $x_{1e}$ namely $0$ and $\pm \sqrt{-k_1/k_2}$. Linearize the model around the equilibrium point

\begin{equation}
(x_{1e}, x_{2e} ) = (\sqrt{-k_1/k_2}, 0) \nonumber
\end{equation}

Determine system matrix $A$ Express the matrix elements using the system parameter symbols $k_1, k_2$ and $m$. 

\textbf{Answer}

We can use the functions $f_1, f_2$ to condense the right hand side. 

\begin{eqnarray}
\begin{bmatrix}
 \dot{x}_1\\
 \dot{x}_2
\end{bmatrix}= 
\begin{bmatrix}
 x_2  \\
 -\frac{k_1 x_1}{m} - \frac{k_2 x_{1}^3}{m}  
\end{bmatrix}=
\begin{bmatrix}
 f_1(x_1, x_2)  \\
 f_2(x_1, x_2)  
\end{bmatrix} \nonumber
\end{eqnarray}

The linearized system can be determined as:

\begin{eqnarray}
\begin{bmatrix}
 \Delta \dot{x}_1\\
 \Delta \dot{x}_2
\end{bmatrix}= 
\begin{bmatrix}
 \frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2}   \\
 \frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} 
\end{bmatrix}
\begin{bmatrix}
 \Delta x_1  \\
 \Delta x_2  
\end{bmatrix}=
\begin{bmatrix}
 0 & 1   \\
 -\frac{k_1}{m}-\frac{3k_2 x_{1e}^{2}}{m} & 0  
\end{bmatrix}
\begin{bmatrix}
 \Delta x_1  \\
 \Delta x_2  
\end{bmatrix} \nonumber
\end{eqnarray}

Evaluation of the partial derivatives at the equilibrium point gives

\begin{eqnarray}
\begin{bmatrix}
 \Delta \dot{x}_1\\
 \Delta \dot{x}_2
\end{bmatrix}= 
\begin{bmatrix}
 0 & 1   \\
 \frac{2k_1}{m} & 0 
\end{bmatrix}
\begin{bmatrix}
 \Delta x_1  \\
 \Delta x_2  
\end{bmatrix} \nonumber
\end{eqnarray}

Thus,

\begin{equation}
A = 
\begin{bmatrix}
 0 & 1   \\
 \frac{2k_1}{m} & 0 
\end{bmatrix}
\nonumber
\end{equation}

\subsubsection{Exercise 9}

Consider the following longitudinal vehicle nonlinear model : 

\begin{eqnarray}
\frac{d x_1}{dt} = \frac{1}{\tau}x_1 + \frac{ki}{\tau r_w}u \nonumber \\
\frac{d x_2}{dt} = \frac{1}{m} (x_1 - mgf\cos d_1 - \frac{1}{2}\rho C_D a_f x_{2}^2 - mgsin d_1 ) \nonumber \\
y = x_2 \nonumber
\end{eqnarray}

where $x_1$ is the force at the wheels, $x_2$ is the vehicle velocity, $u$ is the input signal, the accelerator pedal position, and $d_1$ is the disturbance, the road slope.

This problem is about determining the equilibrium point $(x_{1e}, x_{2e}, u_e, d_{1e})$ that corresponds to the condition when vehicle is traveling with a velocity of $15 m/s$ on a flat road.

\textbf{Answer}

The equilibrium point is determined by setting the derivatives equal to zero: 
\begin{eqnarray}
0 = -\frac{1}{\tau}x_1+\frac{ki}{\tau r_w}u \nonumber \\
0 =\frac{1}{m}\left ( x_1-mgf\cos{d_1}-\frac{1}{2}\rho C_D A_f x^2_2-mg\sin{d_1}\right ) \nonumber\\
y =x_2 \nonumber 
\end{eqnarray}

From the specification of the exercise we get $(x_{2e}=15)$ and $(d_{1e}=0)$. Using the algebraic equations the other two equilibrium points can be determined as $x_{1e}=\frac{1}{2}\rho C_D A_f x^{2e}_2+m g f$ and 
$u_{e}=\frac{r_w}{k i}$, $x_{1e}=\frac{r_w\rho C_D A_f x^2_{2e}}{2k i}$. If we insert numerical values we get: $(x_{1e},x_{2e},u_{e}, ~~d_{1e})=(3216, 15, 0.2010, 0)$.

\subsubsection{Exercise 10}

Determine the partial derivatives needed for linearizing the the system

\begin{eqnarray}
\frac{d x_1}{dt} = \frac{1}{\tau}x_1 + \frac{ki}{\tau r_w}u = f_1(x_1, x_2, u, d_1) \nonumber \\
\frac{d x_2}{dt} = \frac{1}{m} (x_1 - mgf\cos d_1 - \frac{1}{2}\rho C_D a_f x_{2}^2 - mgsin d_1 ) = f_2(x_1, x_2, u, d_1) \nonumber \\
y = x_2 = h(x_1, x_2, u, d_1) \nonumber
\end{eqnarray}
around the equilibrium point $(x_{1e}, x_{2e}, u_e, d_{1e})$. The linearized system can be determined as


\begin{eqnarray}
\begin{bmatrix}
 \Delta \dot{x}_1\\
 \Delta \dot{x}_2
\end{bmatrix}= 
\begin{bmatrix}
 \frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2}   \\
 \frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} 
\end{bmatrix}
\begin{bmatrix}
 \Delta x_1  \\
 \Delta x_2  
\end{bmatrix} + 
\begin{bmatrix}
 \frac{\partial f_1}{\partial u}    \\
 \frac{\partial f_2}{\partial u}   
\end{bmatrix} \Delta u +
\begin{bmatrix}
\frac{\partial f_1}{\partial d_1}    \\
\frac{\partial f_2}{\partial d_2} 
\end{bmatrix} \Delta d_1 \nonumber \\
\Delta y = 
\begin{bmatrix}
 \frac{\partial h}{\partial x_1} & \frac{\partial h}{\partial x_2}  
\end{bmatrix}
\begin{bmatrix}
 \Delta x_1  \\
 \Delta x_2  
\end{bmatrix} + 
\begin{bmatrix}
  \frac{\partial h}{\partial u}  
\end{bmatrix} \Delta u +
\begin{bmatrix}
\frac{\partial h}{\partial d_1} 
\end{bmatrix} \Delta d_1
\end{eqnarray}

\textbf{Answer}

We will have:

\begin{eqnarray}
\frac{\partial f_1}{\partial x_1}=\frac{\partial }{\partial x_1}(-\frac{1}{\tau}x_1+\frac{ki}{\tau r_w}u)=-\frac{1}{\tau} \nonumber \\
\frac{\partial f_1}{\partial x_2}=\frac{\partial }{\partial x_2}(-\frac{1}{\tau}x_1+\frac{ki}{\tau r_w}u)=0  \nonumber \\
\frac{\partial f_1}{\partial u}=\frac{\partial }{\partial u}(-\frac{1}{\tau}x_1+\frac{ki}{\tau r_w}u)=\frac{ki}{\tau r_w}  \nonumber \\
\frac{\partial f_1}{\partial d_1}=\frac{\partial }{\partial d_1}(-\frac{1}{\tau}x_1+\frac{ki}{\tau r_w}u)=0  \nonumber \\
\frac{\partial f_2}{\partial x_1}=\frac{\partial }{\partial x_1}\frac{1}{m}\left ( x_1-mgf\cos{d_1}-\frac{1}{2}\rho C_D A_f x^2_2-mg\sin{d_1}\right )=\frac{1}{m}  \nonumber \\
\frac{\partial f_2}{\partial x_2}=\frac{\partial }{\partial x_2}\frac{1}{m}\left ( x_1-mgf\cos{d_1}-\frac{1}{2}\rho C_D A_f x^2_2-mg\sin{d_1}\right )=-\frac{\rho C_D A_f x_2}{m}  \nonumber \\
\frac{\partial f_2}{\partial u}=\frac{\partial }{\partial u}\frac{1}{m}\left ( x_1-mgf\cos{d_1}-\frac{1}{2}\rho C_D A_f x^2_2-mg\sin{d_1}\right )=0 \nonumber \\
\frac{\partial f_2}{\partial d_1}=\frac{\partial }{\partial d_1}\frac{1}{m}\left ( x_1-mgf\cos{d_1}-\frac{1}{2}\rho C_D A_f x^2_2-mg\sin{d_1}\right ) =gf\sin{d_{1e}}-g\cos{d_{1e}} \nonumber \\
\frac{\partial h}{\partial x_1}=\frac{\partial }{\partial x_1}x_2=0 \nonumber \\
\frac{\partial h}{\partial x_2}=\frac{\partial }{\partial x_2}x_2=1 \nonumber \\
\frac{\partial h}{\partial u}=\frac{\partial }{\partial u}x_2=0  \nonumber \\
\frac{\partial h}{\partial d_1}=\frac{\partial }{\partial d_1}x_2=0 \nonumber 
\end{eqnarray}

\subsubsection{Exercise 11}

The linearized longitudinal vehicle dynamics model for a vehicle traveling at $20 m/sec$ on a flat road is given by the following state-space model

The number of zeros is 0 as the numerator is constant.

\begin{eqnarray}
\begin{bmatrix}
 \dot{x}_1\\
 \dot{x}_2
\end{bmatrix}= 
\begin{bmatrix}
 -1.25 & 0 \\
 0.000005 & -0.0024 
\end{bmatrix}
\begin{bmatrix}
 x_1\\
 x_2
\end{bmatrix} +  
\begin{bmatrix}
 20000\\
 0
\end{bmatrix}u +
\begin{bmatrix}
 0\\
 -9.82
\end{bmatrix}d_1 \\
y=
\begin{bmatrix}
 0 & 1  \\
\end{bmatrix}
\begin{bmatrix}
 x_1\\
 x_2
\end{bmatrix} 
\end{eqnarray}

where $x_1$ is the force at the wheels, $x_2$ is the vehicle velocity, $u$ is the input signal and $d_1$ is the disturbance of the road.

Design a state feedback cruise controller using pole placement on the form

\begin{equation}
u = - K x + k_r r
\end{equation}

such that the closed loop system's characteristic polynomial becomes 
\begin{equation}
p(s) = s^2 + 2\zeta \omega_n s +\omega_{n}^{2}  
\end{equation}

where $\omega_n=0.6$ and $\zeta = 1/\sqrt{2}$. The reference gain $k_r$ should be chosen such that the steady state gain is 1. The disturbance $d_1$ can be considered to be 0.

