\section{Extended Kalman Filter}
\label{extended_kalman_filter}

All of  our discussion to this point has considered linear filters for linear systems.
Unfortunately, linear systems do not  exist.  All systems are ultimately nonlinear.

However, many systems are  close enough to linear that linear estimation approaches give satisfactory results. 
But  close enough can only be carried so far.  Eventually, we run across a system 
that does not behave linearly even over a small range of  operation, and our linear 
approaches for  estimation  no longer give good results.  In this case, we  need  to  explore nonlinear estimators. 

Nonlinear filtering can be a difficult and complex subject.  It is certainly not as 
mature, cohesive, or well understood  as linear filtering. There is still a lot of  room 
for advances and improvement in nonlinear estimation techniques.  However, some 
nonlinear  estimation methods have become  (or are becoming) widespread.  These 
techniques  include nonlinear  extensions of  the Kalman filter,  unscented  filtering, 
and particle filtering.

In this section, we will discuss some nonlinear extensions of  the Kalman filter. 
The Kalman filter  that we  discussed earlier  in this book  directly  applies only to 
linear  systems.  However,  a  nonlinear  system  can  be  linearized  as discussed  in 
Section  1.3, and then  linear  estimation  techniques  (such  as the  Kalman  or  $H_{\infty}$, 
filter) can be applied.  This chapter discusses those types of approaches to nonlinear 
Kalman filtering.



\subsection{The Linearized Kalaman Filter }
\label{linearized_kalman_filter}
In  this section, we  will show how  to linearize a nonlinear system, and  then  use 
Kalman  filtering theory to estimate the  deviations  of  the state  from a  nominal 
state value. This will then give us an estimate of the state of the nonlinear system.

We will derive the linearized Kalman filter from the continuowtime viewpoint, but 
the analogous derivation for discretetime or hybrid systems are straightforward.

\subsection{The Extended Kalman Filter }
\label{extended_kalman_filter}

The previous section obtained a linearized Kalman filter for estimating the states of 
a nonlinear system.  The derivation was based on linearizing the nonlinear system 
around a nominal state trajectory.  The question that arises is, How do we know 
the nominal state trajectory? 

In some cases it may not be straightforward to find 
the nominal trajectory.  However, since the Kalman  filter estimates the state of 
the system, we can use the Kalman filter estimate as the nominal state trajectory.

This is sort of a bootstrap method.  We linearize the nonlinear system around the 
Kalman filter estimate, and the Kalman filter estimate is based on the linearized 
system. This is the idea of the extended Kalman filter (EKF), which was originally 
proposed by Stanley Schmidt so that the Kalman filter could be applied to nonlinear 
spacecraft navigation problems.


However, the linear Kalman filter cannot be used directly
to estimate states that are nonlinear functions of either
the measurements or the control inputs. For example, the pose of the car includes its orientation which is
a nonlinear quantity, orientations in 3D live
on a sphere, in fact. 

Thus, we need to look for something else.  The EKF is designed to work with nonlinear systems and it's often
considered one of the workhorses of state estimation because it's used in all sorts of applications
including self-driving cars. 

The filter works by first predicting the mean and covariance of
the updated state estimate at some time step $k$ based on the previous state and any inputs
we give to the system, such as the position of
the accelerator pedal. The filter then uses a
measurement model to predict what measurements
should arrive based on the state estimate and compares
these predictions with the measurements that actually
arrive from our sensors. The Kalman gain $K$ tells us how to weight
all of these pieces of information, so that we can optimally combine
them into a corrected estimate, that is, a new state and
an updated co-variance. This is sometimes called a
predictor-corrector architecture. As we already know, the Kalman filter is actually the best of all possible estimators
for linear systems. Unfortunately, there is a catch. Linear systems don't exist in reality. Even a very simple system like a resistor with a voltage
applied is not truly linear, at least not all the time. For a certain range of voltages, the current is a linear function of
the voltage and follows Ohm's Law. But as the voltage gets higher, the resistor heats up which alters
the resistance in a nonlinear way. Since the systems that we encounter
in practice are nonlinear, this raises an important question. Can we still use the Kalman filter
for nonlinear systems? If so, how? 

\section{Linearization}

The key concept in the Extended Kalman Filter is the idea of linearizing
a nonlinear system. For this reason, the EKF is sometimes referred to as the
Linearized Kalman filter. Linearizing a system just means
picking some operating point $\alpha$ and finding a linear approximation to the nonlinear function $f$ in
the neighborhood of $\alpha$. In two dimensions, this means
finding the tangent line to the function $f(x)$ when $x = \alpha$. Mathematically, we do this by taking the Taylor series expansion
of the function. 



\begin{framed}
\theoremstyle{remark}
\begin{remark}{\textbf{Taylor Series Expansion}}

The Taylor series expansion is a way of representing a function
as an infinite possibly, some whose terms are calculated from the function's derivatives
at a single point.


\begin{equation}
f(x) \approx f(\alpha) + \frac{\partial f}{\partial x} \|_{x=\alpha} (x-\alpha) + \frac{1}{2!}\frac{\partial^2 f}{\partial x^2} \|_{x=\alpha} (x-\alpha)^2 + \ldots
\end{equation}

\end{remark}
\end{framed}

For linearization, we're only interested in the first order terms of the Taylor
series expansion. 

Let's return to our general nonlinear motion and measurement models and
try to linearize them. What should we choose as the operating
point for our Taylor's expansion? Ideally, we would like to linearize
the models about the true value of the state but we can't do that because if we already knew
the true value of the state, we wouldn't need to estimate it. Instead, let's pick
the next best thing, the most recent estimate of the state. For our emotion model, we'll linearize about
the posterior estimate of the previous state and
for the measurement model, we'll linearize about our prediction of the current state based
on the motion model.




\begin{equation}
\mathbf{x}_k = f_{k-1}(\mathbf{x}_{k-1}, \mathbf{u}_{k-1}, \mathbf{w}_{k-1}) \approx f_{k-1}(\hat{\mathbf{x}}_{k-1}, \mathbf{u}_{k-1}, \mathbf{0}) + \frac{\partial f_{k-1}}{\partial x_{k-1}} \|_{\hat{\mathbf{x}}_{k-1}} (x-\alpha)
\end{equation}


\begin{equation}
\mathbf{y}_k = h_k(\mathbf{x}_k, \mathbf{v}_k) \approx h_k(\check{\mathbf{x}}_k, \mathbf{0}) + \frac{\partial h_k}{\partial x_k} \|_{\check{\mathbf{x}}_{k-1}, \mathbf{0}} (\mathbf{x}_k-\check{\mathbf{x}}_k) + \frac{\partial h_k}{\partial \mathbf{v}_k} \|_{\check{\mathbf{x}}_k, \mathbf{0}} \mathbf{v}_k
\end{equation}

 So, now we have a linear system in
state space and the matrices $F, L, H$ and $M$ are called Jacobian
matrices of the system. Computing these matrices correctly is the most important and difficult step in the Extended Kalman filter or EKF algorithm, and it's also the most common
place to make mistakes. 

\begin{framed}
\theoremstyle{remark}
\begin{remark}{\textbf{Jacobian Matrix}}

In vector calculus, a Jacobian or Jacobian matrix is the matrix of all
first-order partial derivatives of a vector valued function. Each column of the Jacobian
contains the derivatives of the function outputs with
respect to a given input. For example, if your function takes a three-dimensional vector and
spits out a two-dimensional vector, the Jacobian would be
a two by three matrix. Intuitively, the Jacobian matrix
tells you how fast each output of your function is changing
along each input dimension, just like how the derivative
of a scalar function tells you how fast the output is
changing as you vary the input. The Jacobian is really
just a generalization of the first derivative
to multiple dimensions. 

Here's a simple example
of the Jacobian of a two-dimensional function with two inputs. 


The Jacobian matrix captures
the first derivatives of each of the two output variables with respect
to each of the two input variables. The best way to get comfortable with
driving Jacobian is just practice. 

\begin{equation}
\mathbf{f}(\mathbf{x}) = 
\begin{bmatrix}
f_1 \\
f_2
\end{bmatrix} = 
\begin{bmatrix}
x_1 + x_2 \\
x_{1}^2
\end{bmatrix}
\end{equation}


\end{remark}
\end{framed}

Now, we know how to compute the
Jacobian matrices needed for the EKF, and all that's left is to plug them into our standard Kalman
filter equations. There are a couple of
differences to notice in the EKF equations compared to the Kalman filter equations
we saw in module two. First, in the prediction
and correction steps, we're still using the nonlinear models
to propagate the mean of the state estimate and to compute
the measurement residual or innovation. That's because we
linearized our motion model about the previous state estimate, and we linearized the measurement model
about the predicted state. By definition,
the linearized model exactly coincides with the nonlinear model
at the operating points. The second difference
is the appearance of the L and M Jacobians related to
the process and measurement noise. In many cases, both of these matrices
will be identity since noise is often assumed to be additive
but this is not always the case. So far, this has all been very abstract. So, let's walk through a concrete
example of actually using the EKF. We'll use the same example from
module two but with a twist. We're going to track the position and velocity of a car moving along a rail. But now, instead of receiving periodic GPS measurements
that tell us our position, we're going to use
an on-board sensor like a camera to measure the altitude of distant
landmarks relative to the horizon. We'll keep the same linear motion model
as in the original example, and assume we know both the height of the landmark and its position
in a global reference frame. Because our sensor is measuring an angle, our measurement model has a nonlinear dependence on
the position of the car. We're going to need to linearize the measurement model and use it
in our Extended Kalman Filter. The Jacobians for
this problem look like this. Notice that the F matrix
in this problem is exactly the same as the F matrix
in the original problem. That's because our motion model
is already linear in the state. Also notice that
the noise Jacobians, L and M, are both identity since both the emotion and the measurement
model have additive noise. Try using the data given here
to estimate the position of the vehicle at time one using the EKF. Here is the result of the prediction step for the mean and
co-variance of the state. Notice that the result is identical to the linear Kalman filter case because
the motion model actually is linear. For the correction step, this is what you should get. Keep in mind that you should use the nonlinear measurement model to
compute the measurement residual, not the linearized model. Also note that in this case, even though the corrected mean at the state estimate is different
from the predicted mean, the corrected co-variance didn't change that much from the predicted co-variance. This is because the Azimuth angle
changes slowly at this distance and doesn't provide
much information about the vehicle state compared
to a GPS measurement. So, to recap, we saw that
the Extended Kalman Filter or EKF uses linearization to adopt
the Kalman filter to nonlinear systems. We'll encounter several
different nonlinear systems to which we can apply
the EKF or its cousin, the UKF, in the upcoming course project. Linearization works by computing
a local linear approximation to a nonlinear function using a first-order Taylor series expansion
about an operating point. This requires several Jacobian matrices which contain the set of
first-order partial derivatives. In the next video, we'll discuss an
alternative formulation of the EKF called the error
state Extended Kalman Filter. This would be a useful tool later
in the course when we talk about estimating the vehicle
orientation in 3D space.